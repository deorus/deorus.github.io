<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kafka | Alex Rodrigues]]></title>
  <link href="http://deorus.github.io/blog/categories/kafka/atom.xml" rel="self"/>
  <link href="http://deorus.github.io/"/>
  <updated>2015-03-05T09:13:58+00:00</updated>
  <id>http://deorus.github.io/</id>
  <author>
    <name><![CDATA[Alex Rodrigues]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Going event-driven with Kafka in two weeks - Part II]]></title>
    <link href="http://deorus.github.io/blog/2013/07/04/going-event-driven-with-kafka-in-two-weeks-part-ii/"/>
    <updated>2013-07-04T18:03:00+01:00</updated>
    <id>http://deorus.github.io/blog/2013/07/04/going-event-driven-with-kafka-in-two-weeks-part-ii</id>
    <content type="html"><![CDATA[<p>In the <a href="/blog/2013/06/28/going-event-driven-with-kafka-in-two-weeks-part-i/">first part</a>, I&rsquo;ve described the motivations and requirements for the transition into a event-driven architecture. In this post, I am going to talk about how to perform distributed counting and how Kafka partitioning is handy for this kind of task.</p>

<h2>Online group-by operations</h2>

<p>As mentioned on <a href="/blog/2013/06/28/going-event-driven-with-kafka-in-two-weeks-part-i/">part one</a>, each consumer will receive messages from a set of partitions in a way that each partition will have only one consumer. The subscriber process can then have a consumer stream per thread and can co-operate with other instances running on other machines by defining each consumer to belong to the same consumer group. There no gain on having the total number of threads in the consumer cluster higher than the number of partitions, as each partition will comunicate at most through one consumer stream.</p>

<!-- more -->


<p><img src="/images/kafka_subscriber_cluster1.png" width="350" title="A Kafka stream with more than one partition" >
<img src="/images/kafka_subscriber_cluster2.png" width="350" title="A Kafka subscriber cluster with spare threads" ></p>

<p>Each consumer thread receives a message from a partition. The message is parsed into a POJO that will be a key to a counting hash map.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Parsing a message from Kafka stream. </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">ConsumerIterator</span><span class="o">&amp;</span><span class="n">lt</span><span class="o">;</span><span class="kt">byte</span><span class="o">[],</span> <span class="kt">byte</span><span class="o">[]&gt;</span> <span class="n">it</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="na">iterator</span><span class="o">();&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">while</span> <span class="o">(</span><span class="n">it</span><span class="o">.</span><span class="na">hasNext</span><span class="o">())</span> <span class="o">{&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">String</span> <span class="n">value</span> <span class="o">=</span> <span class="k">new</span> <span class="n">String</span><span class="o">(</span><span class="n">it</span><span class="o">.</span><span class="na">next</span><span class="o">().</span><span class="na">message</span><span class="o">());</span>
</span><span class='line'><span class="kd">final</span> <span class="n">String</span><span class="o">[]</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot;;&quot;</span><span class="o">,</span> <span class="o">-</span><span class="mi">1</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// ...</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>The example above shows how to parse a message, assuming it&rsquo;s a comma-separated value string. To create a compatible system with the existing log based solution and for debugging purposes, we first adopt the old CSV as message format. However, other solutions exist such as <a href="https://code.google.com/p/kryo/">Kryo</a>, <a href="http://avro.apache.org/">Avro</a> and <a href="http://thrift.apache.org/">Thrift</a>.</p>

<p>The parsed POJO is the counter key and it has a custom hashCode method implementation. The hashCode is invoked by the Java&rsquo;s HashMap and it uses the returning value to locate the value internally. When more than one entry exists with the same hashCode, the equals method is used to determine the equality to the query key.</p>

<p>To aggregate the counts by a set of attributes, we can use the hashCode and equals methods. These methods must have a consistent behaviour considering two objects to be equal if the set of group-by attributes have identical values in both. The hashCode calculation has to take this values into account, as shown in the snippet below.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Example of a GroupBy by hour and category. </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">import</span> <span class="nn">org.apache.commons.lang3.builder.EqualsBuilder</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.commons.lang3.builder.HashCodeBuilder</span><span class="o">;&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SaleEventByHourAndCategory</span> <span class="kd">extends</span> <span class="n">SaleEvent</span> <span class="o">{&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="kd">static</span> <span class="kd">final</span> <span class="n">TimeZone</span> <span class="n">GMT_TZ</span> <span class="o">=</span> <span class="n">TimeZone</span><span class="o">.</span><span class="na">getTimeZone</span><span class="o">(</span><span class="s">&quot;GMT:00&quot;</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="kd">protected</span> <span class="n">Long</span> <span class="nf">getHour</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="c1">// consider move this to a Util class</span>
</span><span class='line'>    <span class="n">Calendar</span> <span class="n">calendar</span> <span class="o">=</span> <span class="n">Calendar</span><span class="o">.</span><span class="na">getInstance</span><span class="o">(</span><span class="n">GMT_TZ</span><span class="o">);</span>
</span><span class='line'>    <span class="n">calendar</span><span class="o">.</span><span class="na">setTime</span><span class="o">(</span><span class="k">new</span> <span class="n">Date</span><span class="o">(</span><span class="n">getUnixTimestamp</span><span class="o">()));</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">calendar</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">Calendar</span><span class="o">.</span><span class="na">MINUTE</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
</span><span class='line'>    <span class="n">calendar</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">Calendar</span><span class="o">.</span><span class="na">SECOND</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
</span><span class='line'>    <span class="n">calendar</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">Calendar</span><span class="o">.</span><span class="na">MILLISECOND</span><span class="o">,</span> <span class="mi">0</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">Long</span><span class="o">.</span><span class="na">valueOf</span><span class="o">(</span><span class="n">calendar</span><span class="o">.</span><span class="na">getTime</span><span class="o">().</span><span class="na">getTime</span><span class="o">());</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="nd">@Override</span>
</span><span class='line'><span class="kd">public</span> <span class="kt">int</span> <span class="nf">hashCode</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">HashCodeBuilder</span><span class="o">()</span>
</span><span class='line'>        <span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">getHour</span><span class="o">())</span>
</span><span class='line'>        <span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">getCategoryId</span><span class="o">())</span>
</span><span class='line'>        <span class="o">.</span><span class="na">hashCode</span><span class="o">();</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="nd">@Override</span>
</span><span class='line'><span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">equals</span><span class="o">(</span><span class="n">Object</span> <span class="n">obj</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">(</span><span class="n">obj</span> <span class="k">instanceof</span> <span class="n">SaleEventByHourAndCategory</span> <span class="o">==</span> <span class="kc">false</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">return</span> <span class="kc">false</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span> <span class="k">if</span> <span class="o">(</span><span class="k">this</span> <span class="o">==</span> <span class="n">obj</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">return</span> <span class="kc">true</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">final</span> <span class="n">SaleEventByHourAndCategory</span> <span class="n">otherObject</span> <span class="o">=</span> <span class="o">(</span><span class="n">SaleEventByHourAndCategory</span><span class="o">)</span> <span class="n">obj</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nf">EqualsBuilder</span><span class="o">()</span>
</span><span class='line'>        <span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">getHour</span><span class="o">(),</span> <span class="n">otherObject</span><span class="o">.</span><span class="na">getHour</span><span class="o">())</span>
</span><span class='line'>        <span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">getCategoryId</span><span class="o">(),</span> <span class="n">otherObject</span><span class="o">.</span><span class="na">getCategoryId</span><span class="o">())</span>
</span><span class='line'>        <span class="o">.</span><span class="na">isEquals</span><span class="o">();</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>The implementation of hashCode and equals use the <a href="http://commons.apache.org/proper/commons-lang/">Apache Commons Lang</a> library.</p>

<h2>Counter Map Implementations</h2>

<p>Each consumer thread will count the events in a shared data structure, to avoid spending too much memory with multiple duplicated entries in each thread&rsquo;s counter map. <a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ConcurrentHashMap.html">ConcurrentHashMap</a> is a native JVM implementation that aims to reduce contention by splitting the key space in blocks. Each block will have a lock to control the write accesses.</p>

<p>Other alternative HashMap implementation is the <a href="http://www.cs.rice.edu/~javaplt/javadoc/concjunit4.7/org/cliffc/high_scale_lib/NonBlockingHashMap.html">NonBlockingHashMap</a>, written by <a href="http://www.azulsystems.com/">Azul System</a>&rsquo;s Dr. Cliff Click, is an implementation that doesn&rsquo;t assure full consistency ruturning only the result of the last completed update operation. This behaviour is lock free and leverage compare and set/swap operations to allow multiple update operations. A benchmark between both implementations can be found <a href="http://leapchasm.com/blog/2012/02/10/concurrent-hashmap-benchmark/">here</a>.</p>

<h2>Aggregated Result Flushing</h2>

<p>The computed operations, either counts, sums or averages are hold in each subscriber process&rsquo;s memory and must be flushed to a proper persistent storage.
We decided to continue with MySQL to avoid porting all the existent visualization tools. In a scenario of multiple instances of the subscriber process, each instance will have a partial result of the aggregated operation. If there are two processes with 20 threads each, each one will have the count for the messages received from half the partitions. Because they only know part of the result, flushing must be done using an UPDATE SQL query or an INSERT in the case of non-existence of that key. To save the check of existence, an <a href="http://dev.mysql.com/doc/refman/5.0/en/insert-on-duplicate.html">INSERT ON DUPLICATE KEY UPDATE</a> is used.</p>

<p><img src="/images/kafka_results_flushing_flow.png" width="700" title="Data flow of aggregated operation results" ></p>

<p>In the first experiments, the subscriber processes flushed the in-memory counts to the same database. However, some of these subscribers were consuming from a broker in Europe region and had to upload the results to a US datacenter-based MySQL instance. To optimize the flow, all the subscribers will act as producers and will publish their partial results into a separate topic. This topic will be read by a single flusher process.</p>

<p>This change of approach improved the throughtput of MySQL ingestion, because less write transations fail. The flusher process executes transaction after transaction in batches of 2000 queries and has a consistent per batch execution time. The partial results publishing is done to the US broker using <a href="https://code.google.com/p/kryo/">Kryo</a> to serialize and Snappy to compress. This attempts to reduce both the bandwidth required and the latency time.</p>

<p>In this post, I&rsquo;ve covered how to do group-by aggregation operations in-memory and temporarily flush them to a persistent engine, such as MySQL. In the next post I&rsquo;ll cover infrastructure matters and deployment of the Kafka stack in AWS.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Going event-driven with Kafka in two weeks - Part I]]></title>
    <link href="http://deorus.github.io/blog/2013/06/28/going-event-driven-with-kafka-in-two-weeks-part-i/"/>
    <updated>2013-06-28T00:47:00+01:00</updated>
    <id>http://deorus.github.io/blog/2013/06/28/going-event-driven-with-kafka-in-two-weeks-part-i</id>
    <content type="html"><![CDATA[<p>During the last couple weeks I&rsquo;ve been working on a project that involves the transformation of a batch-based data pipeline into an event-driven one.</p>

<p>I am working in real-time advertisement industry and most of the reports generated require processing huge amounts of data. The reports are essentially counting events for traffic estimation or classification. However, counting a thousand events per second, in a distributed environment might not be as trivial as it seems.</p>

<p>The old process ingested hourly logs, captured from some dozens of nodes every hour. Each node uploaded a compressed bulk of log files to AWS S3, and Hadoop jobs triggered every hour had to load them up again into HDFS. The whole time spent in this IO-dependent ETL process was considerably huge and the increasing amount of data was causing a delay of several hours to get reporting metrics ready.</p>

<p>In real-time bidding, the reporting data of some hours ago might become totally useless for the current bidding decisions, as the market and the opportunities in inventory vary a lot, depending on the countries you serve ads and depending also on the time of the day.</p>

<p>The latency and the time-based utility of reporting data motivated the change into an event-driven pipeline.</p>

<!-- more -->


<h2>Requirements</h2>

<p>In order to keep business running, the new system had to be implemented in parallel with the batch pipeline. The first change was to gather data directly from each node into a message broker and have a set of consumers processing the data.</p>

<p>In the first phase, messages could be simply gathered with a <code>tail -f</code> in the log files and the output piped with a message publisher application that reads them from the input stream.</p>

<p>The message queue system had to be able to deliver messages with high-throughput rather than low-latency and had to persist them to disk, as it was meant to replace the file based logging pipeline. Logging to network inside a datacenter can be faster than logging to disk (see <a href="https://gist.github.com/hellerbarde/2843375" title="Latency numbers every programmer should know">Latency numbers every programmer should know</a>, by Peter Norvig and Jeff Dean).</p>

<p>Message global ordering wasn&rsquo;t really a requirement for the volume estimation processing, as each opportunity event contains a timestamp we can use to group counts by.</p>

<p>For volume estimation, data loss up to some seconds is also acceptable in a failure scenario, as even if we miscount some events, most of them get will be counted.</p>

<h2>Apache Kafka</h2>

<p>After analysing the most popular, open-source available queueing solutions I could conclude that most of them focused on low-latency message deliver and just a few supported persistence. <a href="http://kafka.apache.org/" title="Apache Kafka">Apache Kafka</a> was the one that seemed to match our requirements.</p>

<p>Kafka started as a LinkedIn in-house project, developed when the company was passing through a similar period of transition when pure batch processing started to affect the feedback loop and become a pain to the business.</p>

<p>Kafka is a distributed message publishing/subscribing system of one or more brokers, each one with a set of zero or more partitions for each existing topic. Kafka persists periodically messages to disk, so in case of failure the last ones might get loss. This speeds up the publishing operation, as publishers don&rsquo;t need to wait until that data gets written to disk.</p>

<p>When a publisher connects to a Kafka cluster, it queries which partitions exist for the topic and which nodes are responsible for each partition.</p>

<p>Each publisher then acts like a card dealer in a poker game, handing messages to partitions as if they were cards. They assign messages to each partition using an hashing algorithm and deliver them to the broker responsible for that partition.</p>

<p>For each partition, a broker stores the incoming messages with monoticaly increasing order identifiers and persists the &ldquo;deck&rdquo; to disk using a data structure with access complexity of O(1).</p>

<p>A subscriber is a set of co-operating processes that belong to a consumer-group. Each consumer in the group get assigned a set of partitions to consume from. One key difference to other message queue systems is that each partition is consumed by the same consumer and this allows each consumer to track their progress on consumption on the thread and update it asynchronously.</p>

<p>This simplifies the subscription process as the consumer doesn&rsquo;t need to reply with acknowledgement responses to each &ldquo;card&rdquo; it gets from the partition &ldquo;deck&rdquo; and the broker doesn&rsquo;t need to store for each message, if it was processed or not. Consumers keep track on what they consume and store <em>asynchronously</em> in Zookeeper. This is the key point that allows high-throughput. In case of consumer failure, a new process can start from the last saved point, eventually processing the last messages twice.</p>

<p>The broker subscription API requires the identifier of the last message a consumer had from a given partition and starts to stream from that point on. The constant access time data structures on disk play an important role here to reduce disk seeks.</p>

<p>Both consumer groups and brokers are dynamic, so if the amount of incoming messages increase, you can just add new broker nodes to the list and each of them will contain a defined number of partitions for each topic. According to the number of partitions you have, you can also spawn more subscriber processes if the ones you have can&rsquo;t handle the new partition&rsquo;s messages in a reasonable time.</p>

<p>This kind of flexibility by design reduces the random IO in the broker machines and make the whole Kafka system a very stable one in heavy-load production environments.</p>

<p>In the <a href="/blog/2013/07/04/going-event-driven-with-kafka-in-two-weeks-part-ii/">part II</a> of the series, I will write how consumers perform the distributed count of events.</p>

<!-- and in the [third part](/blog) I will talk a little bit about infrastructure and deployment of Kafka stack on AWS. -->

]]></content>
  </entry>
  
</feed>
